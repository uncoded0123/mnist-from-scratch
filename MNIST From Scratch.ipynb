{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2aefe51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0\n",
      "Loss: 2.254\n",
      "Loss: 0.530\n",
      "Loss: 1.201\n",
      "Loss: 0.477\n",
      "Loss: 0.654\n",
      "Loss: 0.276\n",
      "Loss: 0.160\n",
      "Loss: 0.257\n",
      "Loss: 0.221\n",
      "Loss: 0.207\n",
      "Loss: 0.045\n",
      "Loss: 0.147\n",
      "Loss: 0.555\n",
      "Loss: 0.118\n",
      "Loss: 0.176\n",
      "Loss: 0.036\n",
      "Loss: 0.127\n",
      "Loss: 0.014\n",
      "Loss: 0.327\n",
      "Loss: 0.138\n",
      "Loss: 0.192\n",
      "Loss: 0.395\n",
      "Loss: 0.097\n",
      "Loss: 0.029\n",
      "Loss: 0.170\n",
      "Loss: 0.203\n",
      "Loss: 0.890\n",
      "Loss: 0.254\n",
      "Loss: 0.173\n",
      "Loss: 0.096\n",
      "Loss: 0.038\n",
      "Loss: 0.027\n",
      "Loss: 0.005\n",
      "Loss: 0.016\n",
      "Loss: 0.003\n",
      "Loss: 0.201\n",
      "Loss: 0.017\n",
      "Loss: 0.014\n",
      "epoch=1\n",
      "Loss: 0.242\n",
      "Loss: 0.032\n",
      "Loss: 0.329\n",
      "Loss: 0.121\n",
      "Loss: 0.137\n",
      "Loss: 0.099\n",
      "Loss: 0.228\n",
      "Loss: 0.053\n",
      "Loss: 0.010\n",
      "Loss: 0.007\n",
      "Loss: 0.004\n",
      "Loss: 0.114\n",
      "Loss: 0.214\n",
      "Loss: 0.022\n",
      "Loss: 0.112\n",
      "Loss: 0.004\n",
      "Loss: 0.015\n",
      "Loss: 0.001\n",
      "Loss: 0.008\n",
      "Loss: 0.026\n",
      "Loss: 0.011\n",
      "Loss: 0.264\n",
      "Loss: 0.015\n",
      "Loss: 0.008\n",
      "Loss: 0.158\n",
      "Loss: 0.008\n",
      "Loss: 0.200\n",
      "Loss: 0.079\n",
      "Loss: 0.080\n",
      "Loss: 0.094\n",
      "Loss: 0.007\n",
      "Loss: 0.020\n",
      "Loss: 0.003\n",
      "Loss: 0.005\n",
      "Loss: 0.002\n",
      "Loss: 0.142\n",
      "Loss: 0.011\n",
      "Loss: 0.008\n",
      "epoch=2\n",
      "Loss: 0.224\n",
      "Loss: 0.004\n",
      "Loss: 0.250\n",
      "Loss: 0.075\n",
      "Loss: 0.091\n",
      "Loss: 0.077\n",
      "Loss: 0.234\n",
      "Loss: 0.043\n",
      "Loss: 0.009\n",
      "Loss: 0.005\n",
      "Loss: 0.002\n",
      "Loss: 0.124\n",
      "Loss: 0.160\n",
      "Loss: 0.019\n",
      "Loss: 0.119\n",
      "Loss: 0.003\n",
      "Loss: 0.009\n",
      "Loss: 0.001\n",
      "Loss: 0.007\n",
      "Loss: 0.021\n",
      "Loss: 0.011\n",
      "Loss: 0.231\n",
      "Loss: 0.014\n",
      "Loss: 0.006\n",
      "Loss: 0.158\n",
      "Loss: 0.008\n",
      "Loss: 0.145\n",
      "Loss: 0.063\n",
      "Loss: 0.074\n",
      "Loss: 0.055\n",
      "Loss: 0.005\n",
      "Loss: 0.030\n",
      "Loss: 0.003\n",
      "Loss: 0.005\n",
      "Loss: 0.002\n",
      "Loss: 0.131\n",
      "Loss: 0.012\n",
      "Loss: 0.006\n",
      "epoch=3\n",
      "Loss: 0.169\n",
      "Loss: 0.003\n",
      "Loss: 0.190\n",
      "Loss: 0.060\n",
      "Loss: 0.076\n",
      "Loss: 0.064\n",
      "Loss: 0.219\n",
      "Loss: 0.037\n",
      "Loss: 0.008\n",
      "Loss: 0.004\n",
      "Loss: 0.002\n",
      "Loss: 0.123\n",
      "Loss: 0.124\n",
      "Loss: 0.017\n",
      "Loss: 0.120\n",
      "Loss: 0.003\n",
      "Loss: 0.007\n",
      "Loss: 0.001\n",
      "Loss: 0.005\n",
      "Loss: 0.017\n",
      "Loss: 0.010\n",
      "Loss: 0.206\n",
      "Loss: 0.014\n",
      "Loss: 0.005\n",
      "Loss: 0.158\n",
      "Loss: 0.009\n",
      "Loss: 0.117\n",
      "Loss: 0.054\n",
      "Loss: 0.065\n",
      "Loss: 0.040\n",
      "Loss: 0.004\n",
      "Loss: 0.028\n",
      "Loss: 0.003\n",
      "Loss: 0.004\n",
      "Loss: 0.002\n",
      "Loss: 0.126\n",
      "Loss: 0.014\n",
      "Loss: 0.006\n",
      "epoch=4\n",
      "Loss: 0.128\n",
      "Loss: 0.003\n",
      "Loss: 0.155\n",
      "Loss: 0.048\n",
      "Loss: 0.065\n",
      "Loss: 0.048\n",
      "Loss: 0.205\n",
      "Loss: 0.035\n",
      "Loss: 0.006\n",
      "Loss: 0.004\n",
      "Loss: 0.001\n",
      "Loss: 0.117\n",
      "Loss: 0.102\n",
      "Loss: 0.016\n",
      "Loss: 0.114\n",
      "Loss: 0.003\n",
      "Loss: 0.005\n",
      "Loss: 0.001\n",
      "Loss: 0.004\n",
      "Loss: 0.014\n",
      "Loss: 0.009\n",
      "Loss: 0.184\n",
      "Loss: 0.013\n",
      "Loss: 0.004\n",
      "Loss: 0.151\n",
      "Loss: 0.011\n",
      "Loss: 0.104\n",
      "Loss: 0.048\n",
      "Loss: 0.057\n",
      "Loss: 0.032\n",
      "Loss: 0.003\n",
      "Loss: 0.023\n",
      "Loss: 0.003\n",
      "Loss: 0.004\n",
      "Loss: 0.001\n",
      "Loss: 0.119\n",
      "Loss: 0.014\n",
      "Loss: 0.005\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Get Data\n",
    "train_dataset = torchvision.datasets.MNIST(train=True, download=True, root='./')\n",
    "rand = torch.randperm(train_dataset.data.shape[0])\n",
    "X = train_dataset.data.reshape(-1,28*28)[rand].float()\n",
    "Y = train_dataset.targets[rand]\n",
    "\n",
    "\n",
    "w1 = torch.randn(784,512) / 784**0.5\n",
    "w2 = torch.randn(512,16) / 512**0.5\n",
    "w3 = torch.randn(16,10) / 16**0.5\n",
    "\n",
    "b3 = torch.zeros(10)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "for epoch in range(5):\n",
    "    print(f'{epoch=}')\n",
    "    lr = 0.1 if epoch < 1 else 0.01\n",
    "    loop_count = 0\n",
    "    for i in range(0,len(X),batch_size):\n",
    "        # Forward\n",
    "        zero = torch.tensor([0])\n",
    "        Xb = X[i:i+batch_size] / 255 # 32, 784\n",
    "        Yb = Y[i:i+batch_size]\n",
    "\n",
    "        l1 = Xb@w1\n",
    "        relu1 = torch.maximum(zero, l1)\n",
    "        \n",
    "        l2 = relu1@w2\n",
    "        relu2 = torch.maximum(zero, l2)\n",
    "\n",
    "        logits = relu2@w3 + b3\n",
    "\n",
    "        logit_maxes = logits.max(dim=1, keepdim=True).values # the 1 max value from each row\n",
    "        norm_logits = logits - logit_maxes # makes numbers <= 0 for not too high exp outputs\n",
    "\n",
    "        counts = norm_logits.exp() # e**logits -- top of softmax\n",
    "        counts_sum = counts.sum(dim=1, keepdim=True) # sum e**logits\n",
    "        counts_sum_inv = counts_sum**-1 # place sum e**logits on bottom of softmax\n",
    "        probs = counts * counts_sum_inv # probs = softmax = e**logits / sum e**logits\n",
    "\n",
    "\n",
    "        # Loss\n",
    "        # It's correct classes, then ln, then average\n",
    "        logprobs = probs.log()\n",
    "        loss = -logprobs[range(len(Yb)), Yb].mean()\n",
    "\n",
    "\n",
    "        # Backward\n",
    "        dloss = 1.0\n",
    "        dlogprobs = torch.zeros_like(logprobs)\n",
    "        dlogprobs[range(len(Yb)), Yb] = -1.0 / len(Yb)\n",
    "        dprobs = 1.0 / probs * dlogprobs\n",
    "        dcounts = counts_sum_inv * dprobs\n",
    "        dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
    "        dcounts_sum = -counts_sum**-2 * dcounts_sum_inv\n",
    "        dcounts += dcounts_sum\n",
    "        dnorm_logits = norm_logits.exp() * dcounts\n",
    "        dlogits = dnorm_logits\n",
    "        dlogit_maxes = -dnorm_logits.sum(dim=1, keepdim=True)\n",
    "        dlogits += F.one_hot(logits.max(dim=1).indices, logits.shape[1]) * dlogit_maxes\n",
    "        drelu2 = dlogits@w3.T\n",
    "        dw3 = relu2.T@dlogits\n",
    "        dl2 = (l2 > 0) * drelu2\n",
    "        drelu1 = dl2@w2.T\n",
    "        dw2 = relu1.T@dl2\n",
    "        dl1 = (l1 > 0) * drelu1\n",
    "        dw1 = Xb.T@dl1\n",
    "        db3 = dlogits.sum(0)\n",
    "\n",
    "\n",
    "        # Update\n",
    "        w1 = w1 - lr * dw1\n",
    "        w2 = w2 - lr * dw2\n",
    "        w3 = w3 - lr * dw3\n",
    "        b3 = b3 - lr * db3\n",
    "        \n",
    "        if loop_count %100 == 0:\n",
    "            print(f'Loss: {loss:.3f}')\n",
    "        loop_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "369a3aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.89%\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "# Get Test Data\n",
    "test_dataset = torchvision.datasets.MNIST(train=False, download=True, root='./')\n",
    "rand = torch.randperm(test_dataset.data.shape[0])\n",
    "X_test = test_dataset.data.reshape(-1,28*28)[rand].float()\n",
    "Y_test = test_dataset.targets[rand]\n",
    "\n",
    "batch_size = 32\n",
    "correct = 0\n",
    "total = 0\n",
    "for i in range(0,len(X_test),batch_size):\n",
    "    # Forward\n",
    "    zero = torch.tensor([0])\n",
    "    Xb = X_test[i:i+batch_size] / 255 # 32, 784\n",
    "    Yb = Y_test[i:i+batch_size]\n",
    "\n",
    "    l1 = Xb@w1\n",
    "    relu1 = torch.maximum(zero, l1)\n",
    "    \n",
    "    l2 = relu1@w2\n",
    "    relu2 = torch.maximum(zero, l2)\n",
    "\n",
    "    logits = relu2@w3 + b3\n",
    "\n",
    "    prediction = logits.argmax(dim=1)\n",
    "    correct += (prediction == Yb).sum().item()\n",
    "    total += len(Yb)\n",
    "    \n",
    "accuracy = correct / total\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d525369",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Accuracy: 97.89%\n",
    "with these settings:\n",
    "w1 = torch.randn(784,512) / 784**0.5\n",
    "w2 = torch.randn(512,16) / 512**0.5\n",
    "w3 = torch.randn(16,10) / 16**0.5\n",
    "\n",
    "b3 = torch.zeros(10)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "for epoch in range(5):\n",
    "    print(f'{epoch=}')\n",
    "    lr = 0.1 if epoch < 1 else 0.01'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
