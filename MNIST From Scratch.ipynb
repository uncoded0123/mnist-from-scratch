{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e691311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "\n",
    "\n",
    "# ------------------- Get Data -------------------\n",
    "# 60,000 samples, 28x28 pixels / sample\n",
    "train_dataset = torchvision.datasets.MNIST(train=True, download=True, root='./')\n",
    "train_rand = torch.randperm(train_dataset.data.shape[0]) # for picking random images/labels, like randint except has no repeats\n",
    "train_img_tensors = train_dataset.data.reshape(-1,784)[train_rand]\n",
    "Y = train_dataset.targets[train_rand]\n",
    "\n",
    "# 10,000 samples, 28x28 pixels / sample\n",
    "test_dataset = torchvision.datasets.MNIST(train=False, download=True, root='./')\n",
    "test_rand = torch.randperm(test_dataset.data.shape[0]) # for picking random images/labels, like randint except has no repeats\n",
    "test_img_tensors = test_dataset.data.reshape(-1,784)[test_rand]\n",
    "test_Y = test_dataset.targets[test_rand]\n",
    "\n",
    "\n",
    "# ------------------- Train -------------------\n",
    "zero = torch.tensor(0)\n",
    "batch_size = 32\n",
    "# input nodes batch\n",
    "# 32 x 784\n",
    "X = train_img_tensors[:batch_size].float() / 255\n",
    "\n",
    "h1_nodes = 128\n",
    "w1 = torch.randn((h1_nodes, 784)) / 784**0.5\n",
    "w1.requires_grad_(True)\n",
    "l1 = X@w1.T\n",
    "relu1 = torch.maximum(zero, l1)\n",
    "\n",
    "h2_nodes = 64\n",
    "w2 = torch.randn((h2_nodes, h1_nodes)) / h1_nodes**0.5\n",
    "w2.requires_grad_(True)\n",
    "l2 = relu1@w2.T\n",
    "relu2 = torch.maximum(zero, l2)\n",
    "\n",
    "out_nodes = 10\n",
    "w3 = torch.randn((out_nodes, h2_nodes)) / h2_nodes**0.5\n",
    "w3.requires_grad_(True)\n",
    "logits = relu2@w3.T\n",
    "\n",
    "e_to_the_logits = torch.e**logits\n",
    "e_to_the_logits_sum = torch.sum(e_to_the_logits, dim=1, keepdim=True)\n",
    "e_to_the_logits_sum_inv = e_to_the_logits_sum**-1\n",
    "probs = e_to_the_logits * e_to_the_logits_sum_inv # prob = softmax. softmax is an activation function, as is relu\n",
    "\n",
    "\n",
    "logprobs = probs.log()\n",
    "# ------------------- Loss -------------------\n",
    "\n",
    "# understand this before moving on to anything else\n",
    "# grabs predictions for 32 images, and correct values in each image\n",
    "loss = -logprobs[range(batch_size), Y[:batch_size]].mean()\n",
    "loss\n",
    "\n",
    "# ------------------- Back -------------------\n",
    "\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(batch_size), Y[:batch_size]] = -1/batch_size\n",
    "dprobs = (1 / probs) * dlogprobs\n",
    "de_to_the_logits = e_to_the_logits_sum_inv * dprobs\n",
    "de_to_the_logits_sum_inv = (e_to_the_logits * dprobs).sum(dim=1, keepdim=True)\n",
    "de_to_the_logits_sum = -e_to_the_logits_sum**(-2) * de_to_the_logits_sum_inv\n",
    "de_to_the_logits = de_to_the_logits + de_to_the_logits_sum\n",
    "dlogits = torch.e**logits * de_to_the_logits\n",
    "drelu2 = dlogits @ w3\n",
    "dw3 = dlogits.T @ relu2\n",
    "dl2 = (l2 > 0) * drelu2\n",
    "dw2 = dl2.T @ relu1\n",
    "drelu1 = dl2 @ w2\n",
    "dl1 = (l1 > 0) * drelu1\n",
    "dw1 = dl1.T @ X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bed7df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# After loss computed\n",
    "loss.backward()\n",
    "\n",
    "# Compare your gradients vs PyTorch's\n",
    "print(torch.allclose(dw1, w1.grad, atol=1e-4))\n",
    "print(torch.allclose(dw2, w2.grad, atol=1e-4))\n",
    "print(torch.allclose(dw3, w3.grad, atol=1e-4))\n",
    "# print(torch.allclose(dw1, w1.grad, atol=1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01e7adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  20, 121, 128, 253,\n",
       "        255, 253, 253, 253, 116,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,  34, 107, 107, 200, 252, 252, 252,\n",
       "        253, 252, 252, 252, 249, 119,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0, 133, 235, 252, 252, 252, 252, 252, 252,\n",
       "        253, 252, 252, 252, 252, 198,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,  39, 207, 248, 252, 252, 252, 197, 172,  95,  39,\n",
       "         39,  39, 160, 252, 252, 198,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 121, 252, 252, 217, 199,  87,  17,   0,   0,   0,\n",
       "          0,   0, 226, 252, 252, 163,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,  32, 192,  79,  31,  14,   0,   0,   0,   0,   0,\n",
       "          0,  80, 245, 252, 238,  52,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 107, 252, 252, 185,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 191, 252, 252, 185,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   4,  14,  14,  99, 146, 146,\n",
       "        147, 247, 252, 252, 224, 146,  56,  14,   6,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,  43, 164, 252, 252, 252, 252, 252,\n",
       "        253, 252, 252, 252, 252, 252, 252, 252, 176,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,  45, 162, 253, 253, 253, 253, 253, 253,\n",
       "        255, 253, 253, 253, 253, 253, 253, 253, 253, 120,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,  54, 235, 252, 252, 252, 241, 145, 202,\n",
       "        253, 252, 252, 161, 145,  47, 104, 131,  13,   6,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,  22,  26,  26,  26,  23,   0,  63,\n",
       "        253, 252, 252,  39,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 133,\n",
       "        253, 252, 252,  39,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 133,\n",
       "        253, 252, 227,  29,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3, 158,\n",
       "        253, 252, 158,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  14, 252,\n",
       "        253, 252, 158,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  12, 239,\n",
       "        253, 252,  75,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 127,\n",
       "        253, 190,  11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        253, 145,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# Get Data\n",
    "train_dataset = torchvision.datasets.MNIST(train=True, download=True, root='./')\n",
    "rand = torch.randperm(train_dataset.data.shape[0])\n",
    "X = train_dataset.data.reshape(-1,28*28)[rand]\n",
    "Y = train_dataset.targets[rand]\n",
    "\n",
    "test_dataset.shape, \n",
    "\n",
    "# Forward\n",
    "\n",
    "# Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bab7946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n",
      "tensor(nan, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print((dw1 - w1.grad).abs().max())\n",
    "print((dw2 - w2.grad).abs().max())\n",
    "print((dw3 - w3.grad).abs().max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
