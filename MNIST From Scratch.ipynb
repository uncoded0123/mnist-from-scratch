{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73b18e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rewriting from scratch again parts\n",
    "import torchvision\n",
    "import torch\n",
    "\n",
    "\n",
    "class MNIST01Part2:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get_data(self):\n",
    "        # 60,000 samples, 28x28 pixels / sample\n",
    "        self.train_dataset = torchvision.datasets.MNIST(train=True, download=True, root='./')\n",
    "        train_rand = torch.randperm(self.train_dataset.data.shape[0]) # for picking random images/labels, like randint except has no repeats\n",
    "        self.train_img_tensors = self.train_dataset.data.reshape(-1,784)[train_rand]\n",
    "        self.Y = self.train_dataset.targets[train_rand]\n",
    "        \n",
    "        # 10,000 samples, 28x28 pixels / sample\n",
    "        self.test_dataset = torchvision.datasets.MNIST(train=False, download=True, root='./')\n",
    "        test_rand = torch.randperm(self.test_dataset.data.shape[0]) # for picking random images/labels, like randint except has no repeats\n",
    "        self.test_img_tensors = self.test_dataset.data.reshape(-1,784)[test_rand]\n",
    "        self.test_Y = self.test_dataset.targets[test_rand]\n",
    "\n",
    "    def forward(self):\n",
    "        zero = torch.tensor(0)\n",
    "        self.batch_size = torch.tensor([32])\n",
    "        # input nodes batch\n",
    "        # 32 x 784\n",
    "        self.X = self.train_img_tensors[:self.batch_size] / 255\n",
    "\n",
    "        h1_nodes = 128\n",
    "        w1 = torch.randn((h1_nodes, 784))\n",
    "        w1 = w1 / h1_nodes**0.5\n",
    "        l1 = self.X@w1.T\n",
    "        relu1 = torch.maximum(zero, l1)\n",
    "\n",
    "        h2_nodes = 64\n",
    "        w2 = torch.randn((h2_nodes, h1_nodes))\n",
    "        w2 = w2 / h2_nodes**0.5\n",
    "        l2 = relu1@w2.T\n",
    "        relu2 = torch.maximum(zero, l2)\n",
    "\n",
    "        out_nodes = 10\n",
    "        w3 = torch.randn((out_nodes, h2_nodes))\n",
    "        w3 = w3 / out_nodes**0.5\n",
    "        self.b3 = torch.randn()\n",
    "        logits = relu2@w3.T\n",
    "        \n",
    "        self.counts = torch.e**logits\n",
    "        self.prob =  self.counts / torch.sum(self.counts, dim=1, keepdim=True) # prob = softmax. softmax is an activation function, as is relu\n",
    "        return self.prob\n",
    "    \n",
    "    def cce_loss(self):\n",
    "        self.pre_pre_loss = self.prob[self.Y]\n",
    "        self.nlog = -torch.log(self.pre_pre_loss)\n",
    "        self.loss_top = torch.sum(self.nlog)\n",
    "        self.loss = self.loss_top / self.batch_size\n",
    "\n",
    "        return self.loss\n",
    "    \n",
    "b = MNIST01Part2()\n",
    "# b.get_data()\n",
    "# b.forward()\n",
    "# b.cce_loss()\n",
    "# b.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed736d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b.get_data()\n",
    "# batch_size = 32\n",
    "# X = b.train_img_tensors[:batch_size] / 255\n",
    "# Y = b.Y\n",
    "# zero = torch.tensor(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102abd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h1_nodes = 128\n",
    "# w1 = torch.randn((h1_nodes, 784))\n",
    "# w1 = w1 / h1_nodes**0.5\n",
    "# l1 = X@w1.T\n",
    "# relu1 = torch.maximum(zero, l1)\n",
    "\n",
    "# out_nodes = 10\n",
    "# w2 = torch.randn((out_nodes, h1_nodes)) * 0.0001\n",
    "# logits = relu1@w2.T\n",
    "\n",
    "# probs = torch.e**logits / torch.sum(torch.e**logits, dim=1, keepdim=True) # probs = softmax\n",
    "\n",
    "# loss = -torch.log(probs[range(batch_size),Y[:batch_size]]).mean()\n",
    "# loss\n",
    "\n",
    "\n",
    "# ----------- grads ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e691311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# current focus\n",
    "import torchvision\n",
    "import torch\n",
    "\n",
    "\n",
    "# ------------------- Get Data -------------------\n",
    "# 60,000 samples, 28x28 pixels / sample\n",
    "train_dataset = torchvision.datasets.MNIST(train=True, download=True, root='./')\n",
    "train_rand = torch.randperm(train_dataset.data.shape[0]) # for picking random images/labels, like randint except has no repeats\n",
    "train_img_tensors = train_dataset.data.reshape(-1,784)[train_rand]\n",
    "Y = train_dataset.targets[train_rand]\n",
    "\n",
    "# 10,000 samples, 28x28 pixels / sample\n",
    "test_dataset = torchvision.datasets.MNIST(train=False, download=True, root='./')\n",
    "test_rand = torch.randperm(test_dataset.data.shape[0]) # for picking random images/labels, like randint except has no repeats\n",
    "test_img_tensors = test_dataset.data.reshape(-1,784)[test_rand]\n",
    "test_Y = test_dataset.targets[test_rand]\n",
    "\n",
    "\n",
    "# ------------------- Train -------------------\n",
    "zero = torch.tensor(0)\n",
    "batch_size = torch.tensor([32])\n",
    "# input nodes batch\n",
    "# 32 x 784\n",
    "X = train_img_tensors[:batch_size] / 255\n",
    "\n",
    "h1_nodes = 128\n",
    "w1 = torch.randn((h1_nodes, 784))\n",
    "w1 = w1 / h1_nodes**0.5\n",
    "l1 = X@w1.T\n",
    "relu1 = torch.maximum(zero, l1)\n",
    "\n",
    "h2_nodes = 64\n",
    "w2 = torch.randn((h2_nodes, h1_nodes))\n",
    "w2 = w2 / h2_nodes**0.5\n",
    "l2 = relu1@w2.T\n",
    "relu2 = torch.maximum(zero, l2)\n",
    "\n",
    "out_nodes = 10\n",
    "w3 = torch.randn((out_nodes, h2_nodes))\n",
    "# w3[:,1] += 10 # manually adjusts weights\n",
    "w3 = w3 / out_nodes**0.5\n",
    "logits = relu2@w3.T\n",
    "\n",
    "e_to_the_logits = torch.e**logits\n",
    "probs = e_to_the_logits / torch.sum(e_to_the_logits, dim=1, keepdim=True) # prob = softmax. softmax is an activation function, as is relu\n",
    "\n",
    "\n",
    "# ------------------- Loss -------------------\n",
    "# loss = -torch.log()\n",
    "\n",
    "\n",
    "\n",
    "# understand this before moving on to anything else\n",
    "probs.shape\n",
    "probs[Y[range(batch_size)]].shape\n",
    "Y.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
