{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aefe51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 784])\n",
      "tensor(2.2771)\n",
      "tensor(2.2888)\n",
      "tensor(2.2830)\n",
      "tensor(2.3061)\n",
      "tensor(2.2184)\n",
      "tensor(2.1913)\n",
      "tensor(2.2155)\n",
      "tensor(2.1990)\n",
      "tensor(2.1597)\n",
      "tensor(2.0935)\n",
      "tensor(2.0668)\n",
      "tensor(2.0853)\n",
      "tensor(2.1014)\n",
      "tensor(2.0726)\n",
      "tensor(1.9856)\n",
      "tensor(1.9682)\n",
      "tensor(1.9888)\n",
      "tensor(1.8686)\n",
      "tensor(1.8005)\n",
      "tensor(1.9473)\n",
      "tensor(1.7925)\n",
      "tensor(1.8401)\n",
      "tensor(1.7316)\n",
      "tensor(1.7350)\n",
      "tensor(1.7720)\n",
      "tensor(1.7464)\n",
      "tensor(1.4851)\n",
      "tensor(1.6196)\n",
      "tensor(1.6445)\n",
      "tensor(1.3587)\n",
      "tensor(1.3013)\n",
      "tensor(1.3661)\n",
      "tensor(1.4129)\n",
      "tensor(1.4165)\n",
      "tensor(1.2010)\n",
      "tensor(1.2820)\n",
      "tensor(1.2321)\n",
      "tensor(1.3573)\n",
      "tensor(1.1146)\n",
      "tensor(1.1304)\n",
      "tensor(1.0977)\n",
      "tensor(0.9781)\n",
      "tensor(1.0413)\n",
      "tensor(0.9888)\n",
      "tensor(0.9166)\n",
      "tensor(0.7216)\n",
      "tensor(0.8811)\n",
      "tensor(1.1642)\n",
      "tensor(0.7232)\n",
      "tensor(0.9894)\n",
      "tensor(0.9710)\n",
      "tensor(0.6292)\n",
      "tensor(0.9356)\n",
      "tensor(0.7876)\n",
      "tensor(1.0912)\n",
      "tensor(1.1403)\n",
      "tensor(0.9695)\n",
      "tensor(0.7779)\n",
      "tensor(0.8939)\n",
      "tensor(0.8866)\n",
      "tensor(0.6577)\n",
      "tensor(0.9048)\n",
      "tensor(0.6145)\n",
      "tensor(0.7866)\n",
      "tensor(0.6946)\n",
      "tensor(0.6248)\n",
      "tensor(0.8237)\n",
      "tensor(0.9525)\n",
      "tensor(0.6988)\n",
      "tensor(0.7896)\n",
      "tensor(0.6422)\n",
      "tensor(0.7056)\n",
      "tensor(0.5888)\n",
      "tensor(0.5119)\n",
      "tensor(0.7027)\n",
      "tensor(0.9525)\n",
      "tensor(0.8203)\n",
      "tensor(0.5517)\n",
      "tensor(1.0920)\n",
      "tensor(0.7014)\n",
      "tensor(0.4423)\n",
      "tensor(0.4978)\n",
      "tensor(0.6750)\n",
      "tensor(0.7741)\n",
      "tensor(0.7423)\n",
      "tensor(0.5374)\n",
      "tensor(1.1682)\n",
      "tensor(0.5320)\n",
      "tensor(0.7407)\n",
      "tensor(0.7292)\n",
      "tensor(0.9648)\n",
      "tensor(0.3540)\n",
      "tensor(0.5089)\n",
      "tensor(0.8865)\n",
      "tensor(0.5054)\n",
      "tensor(0.4579)\n",
      "tensor(0.4567)\n",
      "tensor(0.6067)\n",
      "tensor(0.6534)\n",
      "tensor(0.6239)\n",
      "tensor(0.4763)\n",
      "tensor(0.6593)\n",
      "tensor(0.7207)\n",
      "tensor(0.2780)\n",
      "tensor(0.4186)\n",
      "tensor(0.4523)\n",
      "tensor(0.5630)\n",
      "tensor(0.6070)\n",
      "tensor(0.4696)\n",
      "tensor(0.6055)\n",
      "tensor(0.6765)\n",
      "tensor(0.4904)\n",
      "tensor(0.3358)\n",
      "tensor(0.4470)\n",
      "tensor(0.5620)\n",
      "tensor(0.3143)\n",
      "tensor(0.7973)\n",
      "tensor(0.4798)\n",
      "tensor(0.3934)\n",
      "tensor(0.4480)\n",
      "tensor(0.4976)\n",
      "tensor(0.3731)\n",
      "tensor(0.3914)\n",
      "tensor(0.4739)\n",
      "tensor(0.5960)\n",
      "tensor(0.4775)\n",
      "tensor(0.4048)\n",
      "tensor(0.3435)\n",
      "tensor(0.8994)\n",
      "tensor(0.3915)\n",
      "tensor(0.4578)\n",
      "tensor(0.4589)\n",
      "tensor(0.4558)\n",
      "tensor(0.7627)\n",
      "tensor(0.4026)\n",
      "tensor(0.3925)\n",
      "tensor(0.4286)\n",
      "tensor(0.1950)\n",
      "tensor(0.2812)\n",
      "tensor(0.5179)\n",
      "tensor(0.5797)\n",
      "tensor(0.3568)\n",
      "tensor(0.5540)\n",
      "tensor(0.5778)\n",
      "tensor(0.4614)\n",
      "tensor(0.7505)\n",
      "tensor(0.5905)\n",
      "tensor(0.3208)\n",
      "tensor(0.2965)\n",
      "tensor(0.2131)\n",
      "tensor(0.5005)\n",
      "tensor(0.3057)\n",
      "tensor(0.3815)\n",
      "tensor(0.3576)\n",
      "tensor(0.3517)\n",
      "tensor(0.7215)\n",
      "tensor(0.4196)\n",
      "tensor(0.4323)\n",
      "tensor(0.3814)\n",
      "tensor(0.6351)\n",
      "tensor(0.3422)\n",
      "tensor(0.4958)\n",
      "tensor(0.5409)\n",
      "tensor(0.6913)\n",
      "tensor(0.7642)\n",
      "tensor(0.2839)\n",
      "tensor(0.3404)\n",
      "tensor(0.3653)\n",
      "tensor(0.3371)\n",
      "tensor(0.2594)\n",
      "tensor(0.1697)\n",
      "tensor(0.3919)\n",
      "tensor(0.4160)\n",
      "tensor(0.4388)\n",
      "tensor(0.6898)\n",
      "tensor(0.5422)\n",
      "tensor(0.9375)\n",
      "tensor(0.5122)\n",
      "tensor(0.6539)\n",
      "tensor(0.3013)\n",
      "tensor(0.1811)\n",
      "tensor(0.5506)\n",
      "tensor(0.3688)\n",
      "tensor(0.5400)\n",
      "tensor(0.3316)\n",
      "tensor(0.3014)\n",
      "tensor(0.4497)\n",
      "tensor(0.3289)\n",
      "tensor(0.6751)\n",
      "tensor(0.2828)\n",
      "tensor(0.3237)\n",
      "tensor(0.2923)\n",
      "tensor(0.7036)\n",
      "tensor(0.2867)\n",
      "tensor(0.3392)\n",
      "tensor(0.5284)\n",
      "tensor(0.4205)\n",
      "tensor(0.7441)\n",
      "tensor(0.4307)\n",
      "tensor(0.5917)\n",
      "tensor(0.6321)\n",
      "tensor(0.4213)\n",
      "tensor(0.2917)\n",
      "tensor(0.7505)\n",
      "tensor(0.8000)\n",
      "tensor(0.4729)\n",
      "tensor(0.5131)\n",
      "tensor(0.2319)\n",
      "tensor(0.3432)\n",
      "tensor(0.3210)\n",
      "tensor(0.5271)\n",
      "tensor(0.6010)\n",
      "tensor(0.3580)\n",
      "tensor(0.3253)\n",
      "tensor(0.2787)\n",
      "tensor(0.3301)\n",
      "tensor(0.2917)\n",
      "tensor(0.2047)\n",
      "tensor(0.3800)\n",
      "tensor(0.3668)\n",
      "tensor(0.2385)\n",
      "tensor(0.2646)\n",
      "tensor(0.9957)\n",
      "tensor(0.3047)\n",
      "tensor(0.4243)\n",
      "tensor(0.6818)\n",
      "tensor(0.4289)\n",
      "tensor(0.7695)\n",
      "tensor(0.7156)\n",
      "tensor(0.4546)\n",
      "tensor(0.4357)\n",
      "tensor(0.2799)\n",
      "tensor(0.3161)\n",
      "tensor(0.4948)\n",
      "tensor(0.3310)\n",
      "tensor(0.2819)\n",
      "tensor(0.2821)\n",
      "tensor(0.2307)\n",
      "tensor(0.3587)\n",
      "tensor(0.2520)\n",
      "tensor(0.1612)\n",
      "tensor(0.4622)\n",
      "tensor(0.2383)\n",
      "tensor(0.3424)\n",
      "tensor(0.1917)\n",
      "tensor(0.1693)\n",
      "tensor(0.2650)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 72\u001b[0m\n\u001b[1;32m     70\u001b[0m dl1 \u001b[38;5;241m=\u001b[39m (l1 \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m*\u001b[39m drelu1\n\u001b[1;32m     71\u001b[0m dw1 \u001b[38;5;241m=\u001b[39m Xb\u001b[38;5;241m.\u001b[39mT\u001b[38;5;129m@dl1\u001b[39m\n\u001b[0;32m---> 72\u001b[0m db3 \u001b[38;5;241m=\u001b[39m dlogits\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Update\u001b[39;00m\n\u001b[1;32m     76\u001b[0m w1 \u001b[38;5;241m=\u001b[39m w1 \u001b[38;5;241m-\u001b[39m lr \u001b[38;5;241m*\u001b[39m dw1\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Get Data\n",
    "train_dataset = torchvision.datasets.MNIST(train=True, download=True, root='./')\n",
    "rand = torch.randperm(train_dataset.data.shape[0])\n",
    "X = train_dataset.data.reshape(-1,28*28)[rand].float()\n",
    "Y = train_dataset.targets[rand]\n",
    "\n",
    "\n",
    "w1 = torch.randn(784,128) / 784**0.5\n",
    "w2 = torch.randn(128,64) / 128**0.5\n",
    "w3 = torch.randn(64,10) / 64**0.5\n",
    "\n",
    "b3 = torch.zeros(10)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(3):\n",
    "    lr = 0.1 if epoch < 1 else 0.01\n",
    "    for i in range(0,len(X),batch_size):\n",
    "        # Forward\n",
    "        zero = torch.tensor([0])\n",
    "        Xb = X[i:i+batch_size] / 255 # 32, 784\n",
    "        Yb = Y[i:i+batch_size]\n",
    "\n",
    "        l1 = Xb@w1\n",
    "        relu1 = torch.maximum(zero, l1)\n",
    "        \n",
    "        l2 = relu1@w2\n",
    "        relu2 = torch.maximum(zero, l2)\n",
    "\n",
    "        logits = relu2@w3 + b3\n",
    "\n",
    "        logit_maxes = logits.max(dim=1, keepdim=True).values # the 1 max value from each row\n",
    "        norm_logits = logits - logit_maxes # makes numbers <= 0 for not too high exp outputs\n",
    "\n",
    "        counts = norm_logits.exp() # e**logits -- top of softmax\n",
    "        counts_sum = counts.sum(dim=1, keepdim=True) # sum e**logits\n",
    "        counts_sum_inv = counts_sum**-1 # place sum e**logits on bottom of softmax\n",
    "        probs = counts * counts_sum_inv # probs = softmax = e**logits / sum e**logits\n",
    "\n",
    "\n",
    "        # Loss\n",
    "        # It's correct classes, then ln, then average\n",
    "        logprobs = probs.log()\n",
    "        loss = -logprobs[range(len(Yb)), Yb].mean()\n",
    "\n",
    "\n",
    "        # Backward\n",
    "        dloss = 1.0\n",
    "        dlogprobs = torch.zeros_like(logprobs)\n",
    "        dlogprobs[range(len(Yb)), Yb] = -1.0 / len(Yb)\n",
    "        dprobs = 1.0 / probs * dlogprobs\n",
    "        dcounts = counts_sum_inv * dprobs\n",
    "        dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
    "        dcounts_sum = -counts_sum**-2 * dcounts_sum_inv\n",
    "        dcounts += dcounts_sum\n",
    "        dnorm_logits = norm_logits.exp() * dcounts\n",
    "        dlogits = dnorm_logits\n",
    "        dlogit_maxes = -dnorm_logits.sum(dim=1, keepdim=True)\n",
    "        dlogits += F.one_hot(logits.max(dim=1).indices, logits.shape[1]) * dlogit_maxes\n",
    "        drelu2 = dlogits@w3.T\n",
    "        dw3 = relu2.T@dlogits\n",
    "        dl2 = (l2 > 0) * drelu2\n",
    "        drelu1 = dl2@w2.T\n",
    "        dw2 = relu1.T@dl2\n",
    "        dl1 = (l1 > 0) * drelu1\n",
    "        dw1 = Xb.T@dl1\n",
    "        db3 = dlogits.sum(0)\n",
    "\n",
    "\n",
    "        # Update\n",
    "        w1 = w1 - lr * dw1\n",
    "        w2 = w2 - lr * dw2\n",
    "        w3 = w3 - lr * dw3\n",
    "        b3 = b3 - lr * db3\n",
    "        \n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "369a3aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9663\n"
     ]
    }
   ],
   "source": [
    "# Get Test Data\n",
    "test_dataset = torchvision.datasets.MNIST(train=False, download=True, root='./')\n",
    "rand = torch.randperm(test_dataset.data.shape[0])\n",
    "X_test = test_dataset.data.reshape(-1,28*28)[rand].float()\n",
    "Y_test = test_dataset.targets[rand]\n",
    "\n",
    "batch_size = 32\n",
    "correct = 0\n",
    "total = 0\n",
    "for i in range(0,len(X_test),batch_size):\n",
    "    # Forward\n",
    "    zero = torch.tensor([0])\n",
    "    Xb = X_test[i:i+batch_size] / 255 # 32, 784\n",
    "    Yb = Y_test[i:i+batch_size]\n",
    "\n",
    "    l1 = Xb@w1\n",
    "    relu1 = torch.maximum(zero, l1)\n",
    "    \n",
    "    l2 = relu1@w2\n",
    "    relu2 = torch.maximum(zero, l2)\n",
    "\n",
    "    logits = relu2@w3 + b3\n",
    "\n",
    "    prediction = logits.argmax(dim=1)\n",
    "    correct += (prediction == Yb).sum().item()\n",
    "    total += len(Yb)\n",
    "accuracy = correct / total\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
